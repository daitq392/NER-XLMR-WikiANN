{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7349024,"sourceType":"datasetVersion","datasetId":4257619}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ipywidgets seqeval","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nimport torch\nfrom transformers import TrainingArguments\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Load dataset","metadata":{}},{"cell_type":"code","source":"#%cd /kaggle/input/xtremepanx/save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"languages = ['en', 'vi', 'fr', 'nl', 'zh']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"panx_ch = defaultdict(DatasetDict)\nfor lang in languages:\n    panx_ch[lang] = DatasetDict.load_from_disk(f'/kaggle/input/xtremepanx/save/{lang}_datasets')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"panx_ch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = panx_ch[\"vi\"][\"train\"][80]\nprint(example)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.1 Create Tag name","metadata":{}},{"cell_type":"code","source":"tags = panx_ch[\"en\"][\"train\"].features[\"ner_tags\"].feature\n\ndef create_tag_names(batch):\n    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"panx_en = panx_ch[\"en\"].map(create_tag_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices_to_print = [19, 4234, 12904]\n\nfor index in indices_to_print:\n    en_example = panx_en[\"train\"][index]\n    df = pd.DataFrame([en_example[\"tokens\"], en_example[\"ner_tags_str\"]],\n                      ['Tokens', 'Tag names'])\n    print(df)\n    print(\"\\n\" + \"=\"*50 + \"\\n\")  \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Model","metadata":{}},{"cell_type":"markdown","source":"## 2.1. XLMRoberta with Token classification head","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import XLMRobertaConfig\nfrom transformers.modeling_outputs import TokenClassifierOutput\nfrom transformers.models.roberta.modeling_roberta import RobertaModel\nfrom transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n\nclass XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n    config_class = XLMRobertaConfig\n\n    def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        # Load model body\n        self.roberta = RobertaModel(config, add_pooling_layer=False)\n        # Set up token classification head\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        # Load and initialize weights\n        self.init_weights()\n\n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n                labels=None, **kwargs):\n        # Use model body to get encoder representations\n        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n                               token_type_ids=token_type_ids, **kwargs)\n        # Apply classifier to encoder representation\n        sequence_output = self.dropout(outputs[0])\n        logits = self.classifier(sequence_output)\n        # Calculate losses\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n        # Return model output object\n        return TokenClassifierOutput(loss=loss, logits=logits, \n                                     hidden_states=outputs.hidden_states, \n                                     attentions=outputs.attentions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2. Load body config and weights","metadata":{}},{"cell_type":"code","source":"index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\ntag2index = {tag: idx for idx, tag in enumerate(tags.names)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlmr_model_name = \"xlm-roberta-base\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoConfig\n\nxlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n                                         num_labels=tags.num_classes,\n                                         id2label=index2tag, label2id=tag2index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlmr_config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# xlmr_model = (XLMRobertaForTokenClassification\n#               .from_pretrained(xlmr_model_name, config=xlmr_config)\n#               .to(device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Tokenize and align","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Load tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nxlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Tokenize and align labels\nTokenize the inputs into subwords and mask the tag id of subsequent subwords to -100","metadata":{}},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, \n                                      is_split_into_words=True)\n    labels = []\n    for idx, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None or word_idx == previous_word_idx:\n                label_ids.append(-100)\n            else:\n                label_ids.append(label[word_idx])\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_panx_dataset(corpus):\n    return corpus.map(tokenize_and_align_labels, batched=True, \n                      remove_columns=['ner_tags', 'tokens'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"panx_en_encoded = encode_panx_dataset(panx_ch[\"en\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"panx_en_encoded[\"train\"][1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Finetune","metadata":{}},{"cell_type":"markdown","source":"# 4.1. Training Arguments","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"...\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Define Metrics","metadata":{}},{"cell_type":"code","source":"def align_predictions(predictions, label_ids):\n    preds = np.argmax(predictions, axis=2)\n    batch_size, seq_len = preds.shape\n    labels_list, preds_list = [], []\n\n    for batch_idx in range(batch_size):\n        example_labels, example_preds = [], []\n        for seq_idx in range(seq_len):\n            # Ignore label IDs = -100\n            if label_ids[batch_idx, seq_idx] != -100:\n                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n\n        labels_list.append(example_labels)\n        preds_list.append(example_preds)\n\n    return preds_list, labels_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from seqeval.metrics import f1_score\n\ndef compute_metrics(eval_pred):\n    y_pred, y_true = align_predictions(eval_pred.predictions, \n                                       eval_pred.label_ids)\n    return {\"f1\": f1_score(y_true, y_pred)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_f1_score(trainer, dataset):\n    return trainer.predict(dataset).metrics[\"test_f1\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dynamically pad the inputs received, as well as the labels\nfrom transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(xlmr_tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_init():\n    return (XLMRobertaForTokenClassification\n            .from_pretrained(xlmr_model_name, config=xlmr_config)\n            .to(device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env TOKENIZERS_PARALLELISM=false","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wandb login ...","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import EarlyStoppingCallback\n\nearly_stopping_callback = EarlyStoppingCallback(\n    early_stopping_patience=2,  \n    early_stopping_threshold=0.0  \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 4\nbatch_size = 16\nmodel_name = f\"xlm-roberta-base-finetuned-panx\"\n\ntraining_args = TrainingArguments(\n    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs, \n    per_device_train_batch_size=batch_size, \n    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\",\n    save_only_model=True,\n    save_steps=1e6, weight_decay=0.01, disable_tqdm=False, \n    save_strategy=\"epoch\", save_total_limit=1,\n    push_to_hub=True, \n    load_best_model_at_end=True,\n    metric_for_best_model='f1'\n    )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finetune on each language","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer\n\ndef train_model(dataset):\n    train_ds = dataset[\"train\"]\n    valid_ds = dataset[\"validation\"]\n    test_ds = dataset[\"test\"]\n    training_args.logging_steps = len(train_ds) // batch_size\n    \n    trainer = Trainer(model_init=model_init, args=training_args,\n        data_collator=data_collator, compute_metrics=compute_metrics,\n        train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer,\n        callbacks=[early_stopping_callback])\n    trainer.train()\n    if training_args.push_to_hub:\n        trainer.push_to_hub(commit_message=\"Training completed!\")\n    \n    f1_score = get_f1_score(trainer, test_ds)\n    return pd.DataFrame.from_dict(\n        {\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"langs = ['en', 'vi', 'fr', 'nl', 'zh']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n \ngc.collect()\n\nwith torch.no_grad():\n    torch.cuda.empty_cache()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores = defaultdict(dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for lang in langs:\n#     training_args.output_dir = f\"xlm-roberta-base-finetuned-panx-{lang}\"\n#     # Fine-tune on monolingual corpus\n#     ds_encoded = encode_panx_dataset(panx_ch[lang])\n#     #metrics = train_model(ds_encoded)\n#     # Collect F1-scores in common dict\n#     f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finetune on all languages","metadata":{}},{"cell_type":"code","source":"corpora = []\nfor lang in langs:\n    ds_encoded = encode_panx_dataset(panx_ch[lang])\n    corpora.append(ds_encoded)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import concatenate_datasets\n\ndef concatenate_splits(corpora):\n    multi_corpus = DatasetDict()\n    for split in corpora[0].keys():\n        multi_corpus[split] = concatenate_datasets(\n            [corpus[split] for corpus in corpora]).shuffle(seed=42)\n    return multi_corpus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpora_encoded = concatenate_splits(corpora)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\ntraining_args.output_dir = \"xlm-roberta-base-finetuned-panx-all\"\nmodelall = XLMRobertaForTokenClassification.from_pretrained('ladoza03/xlm-roberta-base-finetuned-panx-all')\ntraining_args.num_train_epochs = 100\ntrainer = Trainer(model=modelall, args=training_args,\n    data_collator=data_collator, compute_metrics=compute_metrics,\n    tokenizer=xlmr_tokenizer, train_dataset=corpora_encoded[\"train\"],\n    eval_dataset=corpora_encoded[\"validation\"],\n    callbacks=[early_stopping_callback])\n\ntrainer.train()\ntrainer.push_to_hub(commit_message=\"Training completed!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"modelall = XLMRobertaForTokenClassification.from_pretrained('ladoza03/xlm-roberta-base-finetuned-panx-all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer_all = Trainer(model=modelall, args=training_args,\n    data_collator=data_collator, compute_metrics=compute_metrics,\n    tokenizer=xlmr_tokenizer)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_en = XLMRobertaForTokenClassification.from_pretrained('ladoza03/xlm-roberta-base-finetuned-panx-en')\nmodel_fr = XLMRobertaForTokenClassification.from_pretrained('ladoza03/xlm-roberta-base-finetuned-panx-fr')\nmodel_vi = XLMRobertaForTokenClassification.from_pretrained('ladoza03/xlm-roberta-base-finetuned-panx-vi')\nmodel_nl = XLMRobertaForTokenClassification.from_pretrained('ladoza03/xlm-roberta-base-finetuned-panx-nl')\nmodel_zh = XLMRobertaForTokenClassification.from_pretrained('ladoza03/xlm-roberta-base-finetuned-panx-zh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer_en = Trainer(model=model_en, args=training_args,\n    data_collator=data_collator, compute_metrics=compute_metrics,\n    tokenizer=xlmr_tokenizer)\n\ntrainer_vi = Trainer(model=model_vi, args=training_args,\n    data_collator=data_collator, compute_metrics=compute_metrics,\n    tokenizer=xlmr_tokenizer)\n\ntrainer_fr = Trainer(model=model_fr, args=training_args,\n    data_collator=data_collator, compute_metrics=compute_metrics,\n    tokenizer=xlmr_tokenizer)\n\ntrainer_zh = Trainer(model=model_zh, args=training_args,\n    data_collator=data_collator, compute_metrics=compute_metrics,\n    tokenizer=xlmr_tokenizer)\n\ntrainer_nl = Trainer(model=model_nl, args=training_args,\n    data_collator=data_collator, compute_metrics=compute_metrics,\n    tokenizer=xlmr_tokenizer)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_f1_score(trainer, dataset):\n    return trainer.predict(dataset).metrics[\"test_f1\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_lang_performance(lang, trainer):\n    panx_ds = encode_panx_dataset(panx_ch[lang])\n    return get_f1_score(trainer, panx_ds[\"test\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Zero shot","metadata":{}},{"cell_type":"code","source":"f1_scores = defaultdict(dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores[\"en\"][\"en\"] = evaluate_lang_performance(\"en\", trainer_en)\nprint(f\"F1-score of [en] model on [en] dataset: {f1_scores['en']['en']:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores[\"en\"][\"vi\"] = evaluate_lang_performance(\"vi\", trainer_en)\nprint(f\"F1-score of [en] model on [vi] dataset: {f1_scores['en']['vi']:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores[\"en\"][\"nl\"] = evaluate_lang_performance(\"nl\", trainer_en)\nprint(f\"F1-score of [en] model on [nl] dataset: {f1_scores['en']['nl']:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores[\"en\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer_en)\nprint(f\"F1-score of [en] model on [fr] dataset: {f1_scores['en']['fr']:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores[\"en\"][\"zh\"] = evaluate_lang_performance(\"zh\", trainer_en)\nprint(f\"F1-score of [en] model on [zh] dataset: {f1_scores['en']['zh']:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Monolingual and Multilingual","metadata":{}},{"cell_type":"code","source":"f1_scores[\"vi\"][\"vi\"] = evaluate_lang_performance(\"vi\", trainer_vi)\nprint(f\"F1-score of [vi] model on [vi] dataset: {f1_scores['vi']['vi']:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores[\"fr\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer_fr)\nprint(f\"F1-score of [fr] model on [fr] dataset: {f1_scores['fr']['fr']:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores[\"nl\"][\"nl\"] = evaluate_lang_performance(\"nl\", trainer_nl)\nprint(f\"F1-score of [nl] model on [nl] dataset: {f1_scores['nl']['nl']:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores[\"zh\"][\"zh\"] = evaluate_lang_performance(\"zh\", trainer_zh)\nprint(f\"F1-score of [zh] model on [zh] dataset: {f1_scores['zh']['zh']:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, lang in enumerate(langs):\n    f1_scores[\"all\"][lang] = get_f1_score(trainer_all, corpora[idx][\"test\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_data = {\"all\": f1_scores[\"all\"]}\nf1_scores_df = pd.DataFrame(scores_data).T.round(4)\nf1_scores_df.rename_axis(index=\"Fine-tune on\", columns=\"Evaluated on\",\n                         inplace=True)\nf1_scores_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_data = {\"en\": f1_scores[\"en\"],\n               \"each\": {lang: f1_scores[lang][lang] for lang in langs},\n               \"all\": f1_scores[\"all\"]}\nf1_scores_df = pd.DataFrame(scores_data).T.round(4)\nf1_scores_df.rename_axis(index=\"Fine-tune on\", columns=\"Evaluated on\",\n                         inplace=True)\nf1_scores_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## When zero-shot is better than monolingual model","metadata":{}},{"cell_type":"code","source":"def train_on_subset(dataset, num_samples):\n    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n    valid_ds = dataset[\"validation\"]\n    test_ds = dataset[\"test\"]\n    training_args.logging_steps = len(train_ds) // batch_size\n    \n    trainer = Trainer(model_init=model_init, args=training_args,\n        data_collator=data_collator, compute_metrics=compute_metrics,\n        train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer)\n    trainer.train()\n    if training_args.push_to_hub:\n        trainer.push_to_hub(commit_message=\"Training completed!\")\n    \n    f1_score = get_f1_score(trainer, test_ds)\n    return pd.DataFrame.from_dict(\n        {\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"panx_nl_encoded = encode_panx_dataset(panx_ch[\"fr\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ncolumns = ['num_samples', 'f1_score']\nmetrics_df = pd.DataFrame(columns=columns)\ntraining_args.num_train_epochs = 3\n\nfor num_samples in [250, 500, 1000, 2000, 4000]:\n    subset_metrics = train_on_subset(panx_nl_encoded, num_samples)\n    metrics_df = pd.concat([metrics_df, subset_metrics], ignore_index=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.axhline(0.8017, ls=\"--\", color=\"r\")\nmetrics_df.set_index(\"num_samples\").plot(ax=ax)\nplt.legend([\"Zero-shot from English\", \"Fine-tuned on French\"], loc=\"lower right\")\nplt.ylim((0, 1))\nplt.xlabel(\"Number of Training Samples\")\nplt.ylabel(\"F1 Score\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}